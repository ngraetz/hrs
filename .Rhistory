wilcox_log_approx
wilcox_log_exact
wilcox_add_approx <- wilcox.test(treatment,control,alternative="greater")$p.value
wilcox_add_exact <- wilcox.exact(treatment,control,alternative="greater")$p.value
wilcox_add_approx
treatmet
treatment
wilcox.test(log(treatment),log(control),alternative="greater")$p.value
wilcox.test(log(treatment),log(control),alternative="greater")$p.value
wilcox.test(log(treatment),log(control),alternative="greater")
control
treatment
log(control)
log(treatment)
## Fisher null, multiplicative
t.test(log(treatment),log(control),var.equal=TRUE,alternative="greater")
## 2. (f) Fisher's sharp null with multiplicative treatment model.
## Fisher null, additive
t.test(treatment,control,var.equal=TRUE,alternative="greater")
exp(0.39)
wilcox.test(log(treatment),log(control),conf.int=TRUE)
## 2. (g) Wilcoxon, multiplicative
## Wilcoxon statistic should be identical under additive and multiplicative models, right?
wilcox_log_approx <- wilcox.test(log(treatment),log(control),alternative="greater")$p.value
wilcox_log_approx
wilcox.test(log(treatment),log(control),alternative="greater")
wilcox.test(log(treatment),log(control),conf.int=TRUE)
wilcox.test(log(treatment),log(control),alternative="greater",conf.int=TRUE)
wilcox.test(log(treatment),log(control),alternative="greater")
wilcox.test(log(treatment),log(control),alternative="greater",conf.int=TRUE)
wilcox.test(log(treatment),log(control),conf.int=TRUE)
exp(1.26)
wilcox.test(log(treatment),log(control),alternative="greater")
wilcox.test(log(treatment),log(control),conf.int=TRUE)
## 2. (g) Wilcoxon, multiplicative
## Wilcoxon statistic should be identical under additive and multiplicative models, right?
wilcox.test(log(treatment),log(control),alternative="greater")$p.value
wilcox.exact(log(treatment),log(control),alternative="greater")$p.value
## Fisher null, multiplicative
t.test(log(treatment),log(control),var.equal=TRUE,alternative="greater")
5.134180 - 3.989723
## 2. (f) Compare Fisher's sharp null additive model with multiplicative treatment model.
t.test(log(treatment),log(control),var.equal=TRUE,alternative="greater")
## 2. (f) Compare Fisher's sharp null additive model with multiplicative treatment model.
mult_test <- t.test(log(treatment),log(control),var.equal=TRUE,alternative="greater")
mult_test$estimate
mult_test$parameter
class(mult_test$estimate)
length(mult_test$estimate)
mult_test$estimate[1] - mult_test$estimate[2]
mult_fisher_p <- mult_test$p.value
mult_fisher_effect <- exp(mult_test$estimate[1] - mult_test$estimate[2])
mult_fisher_p <- mult_test$p.value
## 2. (g) Wilcoxon, multiplicative
## Wilcoxon statistic should be identical under additive and multiplicative models, right?
wilcox.test(log(treatment),log(control),conf.int=TRUE)
## 2. (g) Wilcoxon, multiplicative
mult_wilcoxon <- wilcox.test(log(treatment),log(control),conf.int=TRUE)
effect_upper <- mult_wilcoxon$conf.int
mult_fisher_effect <- mult_test$estimate[1] - mult_test$estimate
effect_ci
effect_ci <- mult_wilcoxon$conf.int
## 2. (f) Compare Fisher's sharp null additive model with multiplicative treatment model.
mult_fisher <- t.test(log(treatment),log(control),var.equal=TRUE,alternative="greater")
mult_fisher
mult_wilcoxon <- wilcox.test(log(treatment),log(control),conf.int=TRUE)
effect_ci <- mult_wilcoxon$conf.int
mult_wilcoxon <- wilcox.test(log(treatment),log(control),conf.int=TRUE)
effect_ci <- mult_wilcoxon$conf.int
mult_wilcoxon
exp(1.14)
?t.test
class(treat.effect.samplemean.montecarlo.test.func(treatment,control,10000)
)
length(treat.effect.samplemean.montecarlo.test.func(treatment,control,10000)
)
data.frame(pval=pval,lowerci=lowerci,upperci=upperci);
treat.effect.samplemean.montecarlo.test.func=function(treated.r,control.r,K){
# Create vectors for r and Z, and find total number in
# experiment and number of treated subjects
r=c(treated.r,control.r);
Z=c(rep(1,length(treated.r)),rep(0,length(control.r)));
N=length(r);
m=length(treated.r);
# Observed test statistic
obs.test.stat=mean(r[Z==1])-mean(r[Z==0]);
# Monte Carlo simulatoin
montecarlo.test.stat=rep(0,K);
for(i in 1:K){
treatedgroup=sample(1:N,m);  # Draw random assignment
controlgroup=(1:N)[-treatedgroup];
# Compute test statistic for random assignment
montecarlo.test.stat[i]=mean(r[treatedgroup])-mean(r[controlgroup]);
}
# Monte Carlo p-value is proportion of randomly drawn
# test statistics that are >= observed test statistic
pval=sum(montecarlo.test.stat>=obs.test.stat)/K;
# 95% CI for true p-value based on Monte Carlo p-value
lowerci=pval-1.96*sqrt(pval*(1-pval)/K);
upperci=pval+1.96*sqrt(pval*(1-pval)/K);
data.frame(pval=pval,lowerci=lowerci,upperci=upperci);
}
treat.effect.samplemean.montecarlo.test.func(treatment,control,10000)
treat.effect.samplemean.montecarlo.test.func=function(K,treated.r,control.r){
# Create vectors for r and Z, and find total number in
# experiment and number of treated subjects
r=c(treated.r,control.r);
Z=c(rep(1,length(treated.r)),rep(0,length(control.r)));
N=length(r);
m=length(treated.r);
# Observed test statistic
obs.test.stat=mean(r[Z==1])-mean(r[Z==0]);
# Monte Carlo simulatoin
montecarlo.test.stat=rep(0,K);
for(i in 1:K){
treatedgroup=sample(1:N,m);  # Draw random assignment
controlgroup=(1:N)[-treatedgroup];
# Compute test statistic for random assignment
montecarlo.test.stat[i]=mean(r[treatedgroup])-mean(r[controlgroup]);
}
# Monte Carlo p-value is proportion of randomly drawn
# test statistics that are >= observed test statistic
pval=sum(montecarlo.test.stat>=obs.test.stat)/K;
# 95% CI for true p-value based on Monte Carlo p-value
lowerci=pval-1.96*sqrt(pval*(1-pval)/K);
upperci=pval+1.96*sqrt(pval*(1-pval)/K);
data.frame(pval=pval,lowerci=lowerci,upperci=upperci);
}
p_cis <- rbindlist(lapply(seq(1000,20000,1000), treat.effect.samplemean.montecarlo.test.func, treated.r = treatment, control.r = control))
?geom_ribbon
ggplot(data=p_cis) +
geom_ribbon(aes(x=sims,
ymin=lowerci,
ymax=upperci))
ggplot(data=p_cis) +
geom_ribbon(aes(x=sims,
ymin=lowerci,
ymax=upperci))
p_cis$sims <- seq(1000,20000,1000)
ggplot(data=p_cis) +
geom_ribbon(aes(x=sims,
ymin=lowerci,
ymax=upperci))
p_cis <- rbindlist(lapply(seq(1000,100000,1000), treat.effect.samplemean.montecarlo.test.func, treated.r = treatment, control.r = control))
p_cis$sims <- seq(1000,20000,1000)
ggplot(data=p_cis) +
geom_ribbon(aes(x=sims,
ymin=lowerci,
ymax=upperci))
p_cis$sims <- seq(1000,100000,1000)
ggplot(data=p_cis) +
geom_ribbon(aes(x=sims,
ymin=lowerci,
ymax=upperci))
p_cis <- rbindlist(lapply(seq(1000,10000,100), treat.effect.samplemean.montecarlo.test.func, treated.r = treatment, control.r = control))
p_cis$sims <- seq(1000,10000,100)
ggplot(data=p_cis) +
geom_ribbon(aes(x=sims,
ymin=lowerci,
ymax=upperci))
ggplot(data=p_cis) +
geom_ribbon(aes(x=sims,
ymin=lowerci,
ymax=upperci)) +
labs(title = 'Confidence interval on p-value based on number of simulations')
# mult_fisher <- t.test(log(treatment),log(control),var.equal=TRUE,alternative="greater")
# mult_fisher_effect <- mult_test$estimate[1] - mult_test$estimate
# mult_fisher_p <- mult_test$p.value
treat.effect.samplemean.montecarlo.test.func(10000,log(treatment),log(control))
mean(log(treatment) - log(control))
effect_ci
mult_wilcoxon$estimate
wilcox.test(log(treatment),log(control),conf.int=TRUE)$estimate
class(wilcox.test(log(treatment),log(control),conf.int=TRUE)$estimate)
# Median of the difference between a sample from x and a sample from y.
exp(wilcox.test(log(treatment),log(control),conf.int=TRUE)$estimate)
exp(mean(log(treatment) - log(control)))
log(treatment) - log(control)
mean(log(treatment) - log(control))
wilcox.test(log(treatment),log(control),conf.int=TRUE)
2^8
2^12
2^15
2^14
# Load knitr package and settings
library(knitr)
library(data.table)
library(ggplot2)
library(formatR)
options(scipen=999)
#opts_chunk$set(fig.align='center', tidy=TRUE, tidy.opts=list(blank=TRUE, width.cutoff=40), warning=FALSE,message=FALSE)
#opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
setwd('C:/Users/ngraetz/Documents/repos/causal_inference')
d <- fread('hw_2.csv')
d
d <- fread('hw_2.csv')
d
wilcox.test(d$treatment,d$control,paired=TRUE,alternative="greater")
d$tear
d$treatment
d$control
?wilcox.test
wilcox.test(d$treatment,d$control,paired=TRUE,alternative="less")
(72+68+83+80)-(60+54+52+45)
> T=rep(c(-1,1,-1,1,-1,1,-1,1),2)
>   C=rep(c(-1,-1,1,1,-1,-1,1,1),2)
>   K=rep(c(-1,-1,-1,-1,1,1,1,1),2)
>   y=c(59,74,50,69,50,81,46,79,61,70,58,67,54,85,44,81)
T=rep(c(-1,1,-1,1,-1,1,-1,1),2)
C=rep(c(-1,-1,1,1,-1,-1,1,1),2)
K=rep(c(-1,-1,-1,-1,1,1,1,1),2)
y=c(59,74,50,69,50,81,46,79,61,70,58,67,54,85,44,81)
t
T
T:K
T:K
lm(y~T+C+K+T:C+T:K+C:K+T:C:K)
mean(60,52)
mean(c(60,52))
mean(c(54,45))
police <- data.table(beat=c('u','u','u','m','m','m','i','i','i'),
length=c(5,10,15,5,10,15,5,10,15),
score=34.4,35.5,39.2,30.2,32.4,34.7,20.1,39.4,54.3)
police
police <- data.table(beat=c('u','u','u','m','m','m','i','i','i'),
length=c(5,10,15,5,10,15,5,10,15),
score=c(34.4,35.5,39.2,30.2,32.4,34.7,20.1,39.4,54.3))
police
## Interaction plot (x=length,y=score,color=beat)
ggplot() +
geom_line(data=police,
aes(x=length,
y=score,
color=beat))
## Interaction plot (x=length,y=score,color=beat)
ggplot() +
geom_line(data=police,
aes(x=length,
y=score,
color=beat)) +
labs(x='Length of Human Relations Course',y='Attitude test score',title='Interaction plot of Human Relations Course effect on attitude scores by officer beat assignment')
library(mice)
library(ggplot2)
hrs <- fread('hrsGform.cl_20190129.csv')
hrs[, cohort := as.Date(as.numeric(birthDate), origin = '1960-01-01')]
hrs[, cohort := as.numeric(substr(cohort,1,4))]
hrs[, id := hhidpn]
hrs <- melt(hrs,
id.vars = c('id','cohort','femalehrsGform','whitehrsGform','blackhrsGform','hispanichrsGform','otherhrsGform'),
measure.vars = patterns('age_','cogScore_','sampWeight_'))
setnames(hrs, c('value1','value2','value3'), c('age','cognitive','pweight'))
hrs[, pweight := as.numeric(pweight)]
hrs[, age := as.numeric(age)]
hrs[, cognitive := as.numeric(cognitive)]
hrs[whitehrsGform==1, race := 'white']
hrs[blackhrsGform==1, race := 'black']
hrs[hispanichrsGform==1, race := 'hispanic']
hrs[otherhrsGform==1, race := 'other']
hrs[, age := cut(age, seq(60,95,5))]
hrs[, age := as.numeric(substr(age, 2, 3))]
hrs <- hrs[!is.na(age), ]
library(data.table)
library(lme4)
library(ggplot2)
library(mice)
repo <- 'C:/Users/ngraetz/Documents/repos/hrs'
setwd(repo)
hrs <- fread('hrsGform.cl_20190129.csv')
hrs[, cohort := as.Date(as.numeric(birthDate), origin = '1960-01-01')]
hrs[, cohort := as.numeric(substr(cohort,1,4))]
hrs[, id := hhidpn]
hrs <- melt(hrs,
id.vars = c('id','cohort','femalehrsGform','whitehrsGform','blackhrsGform','hispanichrsGform','otherhrsGform'),
measure.vars = patterns('age_','cogScore_','sampWeight_'))
setnames(hrs, c('value1','value2','value3'), c('age','cognitive','pweight'))
hrs[, pweight := as.numeric(pweight)]
hrs[, age := as.numeric(age)]
hrs[, cognitive := as.numeric(cognitive)]
hrs[whitehrsGform==1, race := 'white']
hrs[blackhrsGform==1, race := 'black']
hrs[hispanichrsGform==1, race := 'hispanic']
hrs[otherhrsGform==1, race := 'other']
hrs[, age := cut(age, seq(60,95,5))]
hrs[, age := as.numeric(substr(age, 2, 3))]
hrs <- hrs[!is.na(age), ]
head(hrs)
head(hrs[order(id)])
length(hrs[is.na(pweight)])
length(hrs[is.na(pweight), pweight])
hrs[, female := femalehrsGform]
## From Courtney
# 1. Mixed effects model of age trajectories of cognition, stratified by race.
# 2. Mixed effects model of age trajectories of cognition, stratified by baseline cognition (3 groups? <10, 10-25, 25-35).
# Covariates for preliminary models:
# Age (also look at non-linear age terms; likely will need quadratic age term)
# Race
# Gender
# Survey period
# Cohort
# I think we should run models with no SES controls, then including SES controls: education, HH income, HH wealth
model1 <- lmer(cognitive ~ female + cohort + (age+age2|id), data=hrs[race=='white', ])
## From Courtney
# 1. Mixed effects model of age trajectories of cognition, stratified by race.
# 2. Mixed effects model of age trajectories of cognition, stratified by baseline cognition (3 groups? <10, 10-25, 25-35).
# Covariates for preliminary models:
# Age (also look at non-linear age terms; likely will need quadratic age term)
# Race
# Gender
# Survey period
# Cohort
# I think we should run models with no SES controls, then including SES controls: education, HH income, HH wealth
hrs[, age2 := age^2]
model1 <- lmer(cognitive ~ female + cohort + (age+age2|id), data=hrs[race=='white', ])
model1 <- lmer(cognitive ~ female + cohort + (age+age2|id), data=hrs[race=='white', ], REML = TRUE)
## Multiple imputation for missing data.
sapply(hrs, function(x) sum(is.na(x)))
mi_list = mice(hrs, method='pmm', m=5)
imp_geo <- as.data.table(imp_geo)
sapply(imp_geo, function(x) sum(is.na(x)))
imp_hrs <- as.data.table(imp_geo)
imp_geo <- mice::complete(mi_list)
length(unique(hrs[!is.na(cognitive), id]))
mi_list <- mice(hrs, method='pmm', m=5)
mi_list <- mice(hrs, m=5)
head(hrs)
grep('hrsGform', names(hrs))
grep('hrsGform', names(hrs), value=T)
hrs[, grep('hrsGform', names(hrs), value=T) := NULL]
head(hrs)
hrs[, age2 := NULL]
mi_list <- mice(hrs, m=5)
head(hrs)
unique(hrs$variable)
hrs[, variable := NULL]
mi_list <- mice(hrs, m=5)
cor(hrs)
cov(hrs)
cor(hrs)
cor(hrs[, C('age','cohort')])
class(hrs)
class(hrs[,1])
class(hrs[1,])
class(hrs$cohort)
class(hrs$age)
cor(hrs[, c('age','cohort')])
head(hrs)
class(hrs$cognitive)
table(hrs$female)
table(hrs$age)
unique(hrs[is.na(cognitive), pweight])
for(v in names(hrs)) message(class(hrs[, get(v)]))
head(hrs)
mi_list <- mice(hrs[, c('cohort','age','cognitive','race','female')], m=5)
imp_geo <- mice::complete(mi_list)
imp_geo <- as.data.table(imp_geo)
sapply(imp_geo, function(x) sum(is.na(x)))
head(imp_geo)
mi_list <- mice(hrs[, c('id','cohort','age','cognitive','race','female')], m=5)
names(imp_hr)
names(imp_hrs)
imp_hrs <- as.data.table(imp_geo)
hrs[, imp_cognitive := imp_hrs[, cognitive]]
head(hrs)
head(hrs[order(id)])
hrs_design <- svydesign(id=~id, weights=~pweight, data=hrs[!is.na(pweight) & !is.na(cognitive), ])
summarize_cognitive <- function(age, stat) {
by_race <- function(r,a) {
## Subset survey design to this age-race.
dsub <- subset(hrs_design, race==r & age==a)
if(stat=='mean') {
s <- as.data.table(merge(svymean(~cognitive, dsub), confint(svymean(~cognitive, dsub))))
names(s) <- c('mean','se','lower','upper')
}
if(stat=='quantile') {
s <- as.data.table(svyquantile(~cognitive, dsub, c(.25,.5,.75)))
names(s) <- c('lower','mean','upper')
}
s[, race := r]
s[, age := a]
return(s)
}
all_race <- rbindlist(lapply(c('white','black'), by_race, a=age))
return(all_race)
}
all <- rbindlist(lapply(unique(hrs[, age]), summarize_cognitive, stat='mean'))
library(survey)
## Exploratory plots of age trajectories
hrs_design <- svydesign(id=~id, weights=~pweight, data=hrs[!is.na(pweight) & !is.na(cognitive), ])
summarize_cognitive <- function(age, stat) {
by_race <- function(r,a) {
## Subset survey design to this age-race.
dsub <- subset(hrs_design, race==r & age==a)
if(stat=='mean') {
s <- as.data.table(merge(svymean(~cognitive, dsub), confint(svymean(~cognitive, dsub))))
names(s) <- c('mean','se','lower','upper')
}
if(stat=='quantile') {
s <- as.data.table(svyquantile(~cognitive, dsub, c(.25,.5,.75)))
names(s) <- c('lower','mean','upper')
}
s[, race := r]
s[, age := a]
return(s)
}
all_race <- rbindlist(lapply(c('white','black'), by_race, a=age))
return(all_race)
}
all <- rbindlist(lapply(unique(hrs[, age]), summarize_cognitive, stat='mean'))
plot1 <- ggplot() +
geom_line(data=all,
aes(y=mean,
x=age,
color=race),
size=2) +
geom_ribbon(data=all,
aes(ymin=lower,
ymax=upper,
x=age,
fill=race),
alpha=0.5) +
ylim(c(0,20)) +
labs(x='Age',y='Population mean',title='Survey-weighted mean cognitive score by age (stratified by race)') +
theme_minimal()
all <- rbindlist(lapply(unique(hrs[, age]), summarize_cognitive, stat='quantile'))
plot2 <- ggplot() +
geom_line(data=all,
aes(y=mean,
x=age,
color=race),
size=2) +
geom_ribbon(data=all,
aes(ymin=lower,
ymax=upper,
x=age,
fill=race),
alpha=0.5) +
ylim(c(0,20)) +
labs(x='Age',y='Population distribution',title='Survey-weighted quantiles of cognitive score (0.25-0.75) by age (stratified by race)') +
theme_minimal()
grid.arrange(plot1, plot2, nrow=1)
library(gridExtra)
r
grid.arrange(plot1, plot2, nrow=1)
summarize_cognitive <- function(age, stat) {
by_race <- function(r,a) {
## Subset survey design to this age-race.
dsub <- subset(hrs_design, race==r & age==a)
if(stat=='mean') {
s <- as.data.table(merge(svymean(~imp_cognitive, dsub), confint(svymean(~cognitive, dsub))))
names(s) <- c('mean','se','lower','upper')
}
if(stat=='quantile') {
s <- as.data.table(svyquantile(~imp_cognitive, dsub, c(.25,.5,.75)))
names(s) <- c('lower','mean','upper')
}
s[, race := r]
s[, age := a]
return(s)
}
all_race <- rbindlist(lapply(c('white','black'), by_race, a=age))
return(all_race)
}
all <- rbindlist(lapply(unique(hrs[, age]), summarize_cognitive, stat='mean'))
plot1 <- ggplot() +
geom_line(data=all,
aes(y=mean,
x=age,
color=race),
size=2) +
geom_ribbon(data=all,
aes(ymin=lower,
ymax=upper,
x=age,
fill=race),
alpha=0.5) +
ylim(c(0,20)) +
labs(x='Age',y='Population mean',title='Survey-weighted mean cognitive score by age (stratified by race)') +
theme_minimal()
all <- rbindlist(lapply(unique(hrs[, age]), summarize_cognitive, stat='quantile'))
plot2 <- ggplot() +
geom_line(data=all,
aes(y=mean,
x=age,
color=race),
size=2) +
geom_ribbon(data=all,
aes(ymin=lower,
ymax=upper,
x=age,
fill=race),
alpha=0.5) +
ylim(c(0,20)) +
labs(x='Age',y='Population distribution',title='Survey-weighted quantiles of cognitive score (0.25-0.75) by age (stratified by race)') +
theme_minimal()
grid.arrange(plot1, plot2, nrow=1)
names(hrs)
## From Courtney
# 1. Mixed effects model of age trajectories of cognition, stratified by race.
# 2. Mixed effects model of age trajectories of cognition, stratified by baseline cognition (3 groups? <10, 10-25, 25-35).
# Covariates for preliminary models:
# Age (also look at non-linear age terms; likely will need quadratic age term)
# Race
# Gender
# Survey period
# Cohort
# I think we should run models with no SES controls, then including SES controls: education, HH income, HH wealth
hrs[, age2 := age^2]
model1 <- lmer(cognitive ~ female + cohort + (age+age2|id), data=hrs[race=='white', ], REML = TRUE)
model1 <- lmer(cognitive ~ female + cohort + (age|id) + (age2|id), data=hrs[race=='white', ], REML = TRUE)
model1 <- lmer(cognitive ~ female + cohort + (1+age|id), data=hrs[race=='white', ], REML = TRUE)
model1 <- lmer(cognitive ~ female + cohort + (1+age|id), data=hrs[race=='white', ], REML = FALSE)
summary(model1)
